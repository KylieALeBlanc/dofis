{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import shutil\n",
    "\n",
    "try:\n",
    "    from .start import data_path\n",
    "except:\n",
    "    data_path = '/Users/kylieleblancKylie/domino/dofis/data/'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def filter_and_rename_cols(df, mydict):\n",
    "    \"\"\"\n",
    "    Keep some original cols from a dataframe, rename them to new column names\n",
    "    Return a new data frame\n",
    "\n",
    "    Arguments:\n",
    "    df = data frame\n",
    "    dict keys = original column names you want to keep\n",
    "    dict values = new column names\n",
    "    \"\"\"\n",
    "    df = df[list(mydict.keys())]\n",
    "    new_df = df.rename(index=str, columns=mydict)\n",
    "    return new_df\n",
    "\n",
    "def fix_parser_error(input_path):\n",
    "    \"\"\"\n",
    "    Some older datasets have observation data across two rows\n",
    "    :param input_path: Location of data set\n",
    "    :return: data set where columns are all in one row\n",
    "    \"\"\"\n",
    "    temp_directory = os.path.join(data_path, 'tea', 'temp')\n",
    "    temp_file = os.path.basename(input_path)\n",
    "    temp_path = os.path.join(temp_directory, temp_file)\n",
    "\n",
    "    print('Got a parser error - concatenating first two lines of text file to remedy!')\n",
    "    shutil.copy(input_path, temp_path)\n",
    "\n",
    "    with open(temp_path, 'r') as file:\n",
    "        text_contents = file.read()\n",
    "    text_contents = text_contents.replace('\\n', '', 1)\n",
    "    with open(temp_path, 'w') \\\n",
    "            as file:\n",
    "        file.write(text_contents)\n",
    "    return (temp_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def clean_cscores(year, subject):\n",
    "    \"\"\"\n",
    "    Reads STAAR scores from\n",
    "    https://tea.texas.gov/student.assessment/staar/aggregate/\n",
    "    :param year: year to read\n",
    "    :param subject: subject to read (see subject_dict keys for subjects\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    # File name\n",
    "    file_yr = year[4:6]\n",
    "    subject_dict = {'3rd': 'e3', '4th': 'e4', '5th': 'e5', '6th': 'e6', '7th': 'e7', '8th': 'e8',\n",
    "                    'Algebra': 'ea1', 'Biology': 'ebi', 'EnglishI': 'ee1', 'EnglishII': 'ee2', 'USHistory': 'eus'}\n",
    "    file_sub = subject_dict[subject]\n",
    "    file = 'cfy' + file_yr + file_sub + '.dat'\n",
    "\n",
    "    # Import writing scores as cscores2\n",
    "    if year in ['yr1112', 'yr1213'] and subject in ['EnglishI', 'EnglishII']:\n",
    "        subject_dict = {'EnglishI': 'ew1', 'EnglishII': 'ew2'}\n",
    "        file = 'cfy' + file_yr + subject_dict[subject] + '.dat'\n",
    "        # need two files for early English scores (reading and writing) TODO: combine reading and writing\n",
    "        try:\n",
    "            cscores2 = pd.read_csv(os.path.join(data_path, 'tea', 'cscores', year, file), sep=\",\")\n",
    "        except:\n",
    "            new_path = fix_parser_error(os.path.join(data_path, 'tea', 'cscores', year, file))\n",
    "            cscores2 = pd.read_csv(new_path, sep=\",\")\n",
    "        # change english name to er\n",
    "        subject_dict = {'EnglishI': 'er1', 'EnglishII': 'er2'}\n",
    "        file = 'cfy' + file_yr + subject_dict[subject] + '.dat'\n",
    "    \n",
    "    # Import files\n",
    "    try:\n",
    "        cscores = pd.read_csv(os.path.join(data_path, 'tea', 'cscores', year, file), sep=\",\")\n",
    "    except:\n",
    "        new_path = fix_parser_error(os.path.join(data_path, 'tea', 'cscores', year, file))\n",
    "        cscores = pd.read_csv(new_path, sep=\",\")\n",
    "    \n",
    "    # Subjects\n",
    "    if subject in ['3rd', '4th', '5th', '6th', '7th', '8th']:\n",
    "        cscores_tokeep = {'DISTRICT': 'district',\n",
    "                          \"r_all_rs\": \"r_\" + subject + \"_avescore\",\n",
    "                          \"r_all_d\": \"r_\" + subject + \"_numtakers\",\n",
    "                          \"m_all_rs\": \"m_\" + subject + \"_avescore\",\n",
    "                          \"m_all_d\": \"m_\" + subject + \"_numtakers\"}\n",
    "    if subject == 'Algebra':\n",
    "        cscores_tokeep = {\"DISTRICT\": \"district\",\n",
    "                          \"a1_all_rs\": \"alg_avescore\",\n",
    "                          \"a1_all_d\": \"alg_numtakers\"}\n",
    "    if subject == 'Biology':\n",
    "        cscores_tokeep = {\"DISTRICT\": \"district\",\n",
    "                          \"bi_all_rs\": \"bio_avescore\",\n",
    "                          \"bi_all_d\": \"bio_numtakers\"}\n",
    "\n",
    "    if subject == 'EnglishI':\n",
    "        if year == 'yr1112' or year == 'yr1213':\n",
    "            cscores['e1_all_rs'] = cscores['r1_all_rs'] + cscores2['w1_all_rs']\n",
    "            cscores['e1_all_d'] = cscores['r1_all_d']\n",
    "        cscores_tokeep = {\"DISTRICT\": \"district\",\n",
    "                          \"e1_all_rs\": \"eng1_avescore\",\n",
    "                          \"e1_all_d\": \"eng1_numtakers\"}\n",
    "\n",
    "    if subject == 'EnglishII':\n",
    "        if year == 'yr1112' or year == 'yr1213':\n",
    "            cscores['e2_all_rs'] = cscores['r2_all_rs'] + cscores2['w2_all_rs']\n",
    "            cscores['e2_all_d'] = cscores['r2_all_d']\n",
    "        cscores_tokeep = {\"DISTRICT\": \"district\",\n",
    "                          \"e2_all_rs\": \"eng2_avescore\",\n",
    "                          \"e2_all_d\": \"eng2_numtakers\"}\n",
    "        \n",
    "    if subject == 'USHistory':\n",
    "        cscores_tokeep = {\"DISTRICT\": \"district\",\n",
    "                          \"us_all_rs\": \"us_avescore\",\n",
    "                          \"us_all_d\": \"us_numtakers\"}\n",
    "\n",
    "    cscores = filter_and_rename_cols(cscores, cscores_tokeep)\n",
    "    if year == 'yr1112':\n",
    "        cscores['district'] = cscores['district'].apply(int)\n",
    "    cscores = cscores.set_index('district')\n",
    "    print(\"There are \", len(cscores), \"districts in \", subject, \"dataset.\")\n",
    "    # num_dups = len(dscores[dscores.index.duplicated(keep = False) == True])\n",
    "    # print('There are', num_dups, ' duplicate indices.')\n",
    "    return cscores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are  2467 districts in  6th dataset.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2467"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = clean_cscores('yr1112', '6th')\n",
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8757"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def clean_cref(year):\n",
    "    \"\"\"\n",
    "    Reads reference data from TABR reports https://rptsvr1.tea.texas.gov/perfreport/tapr/2017/download/DownloadData.html\n",
    "    :param year:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    if year == 'yr1718':\n",
    "        year = 'yr1617'\n",
    "    if year == 'yr1112':\n",
    "        filename = 'cref.dat'\n",
    "    if year == 'yr1213':\n",
    "        filename = 'CREF.txt'\n",
    "    if year >= 'yr1314':\n",
    "        filename = 'CREF.dat'\n",
    "    cref = pd.read_csv(os.path.join(data_path, 'tea', 'cref', year, filename), sep=\",\")\n",
    "    cref_tokeep = {'DISTNAME': 'distname',\n",
    "                   'CAMPUS': 'campus',\n",
    "                   'CAMPNAME': 'campname',\n",
    "                   'CFLCHART': 'campischarter',\n",
    "                   'GRDTYPE': 'grade_range',\n",
    "                   'REGION': 'region'}\n",
    "    if year > 'yr1112':\n",
    "        cref_tokeep['C_RATING'] = 'rating_c'\n",
    "    cref = filter_and_rename_cols(cref, cref_tokeep)\n",
    "    return cref\n",
    "df = clean_cref('yr1718')\n",
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:anaconda]",
   "language": "python",
   "name": "conda-env-anaconda-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
